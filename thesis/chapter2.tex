\chapter{АЛГОРИТМИЧЕСКИЕ ОСНОВЫ ПРОТОКОЛА RAFT}

\section{Концепция реплицированного автомата и архитектура}

Основной задачей алгоритма Raft является построение надежной распределенной системы поверх кластера ненадежных серверов. Для этой цели используется абстракция \textbf{Реплицированного конечного автомата (Replicated State Machine, RSM)}.

Идея RSM заключается в том, что надежность сервиса может быть обеспечена путем размещения копий одного и того же процесса на нескольких независимых физических серверах. Каждый процесс представляет собой детерминированный конечный автомат.

Математически модель описывается следующим образом: если множество детерминированных автоматов начинают работу из идентичного начального состояния $S_0$ и последовательно применяют к нему одну и ту же цепочку входных команд $C = \{c_1, c_2, \dots, c_k\}$, то все они гарантированно перейдут в одинаковое конечное состояние $S_k$ и сгенерируют идентичные выходные данные.

Таким образом, задача поддержания согласованности сложного состояния серверов сводится к задаче согласования их входных данных. Для этого вводится понятие \textbf{реплицированного журнала (Replicated Log)} — линейно упорядоченного списка команд. Алгоритм консенсуса обязан гарантировать, что этот журнал будет идентичен на всех исправных узлах, несмотря на сбои оборудования и задержки сети.

\begin{figure}[H]
	\center{\includegraphics[width=0.7\linewidth]{images/rsm.png}}
	\caption{Модель RSM}
\end{figure}

\section{Базовая архитектура и механизм взаимодействия}

Алгоритм Raft реализует концепцию RSM через модель сильного лидерства. В отличие от симметричных подходов, где любой узел может инициировать изменение состояния, Raft делегирует исключительные полномочия по управлению журналом выделенному координатору — лидеру.

Такая архитектура упрощает управление потоками данных: информация всегда распространяется в одном направлении — от лидера к последователям. Лидер берет на себя ответственность за обработку клиентских запросов, репликацию записей и фиксацию изменений.

\subsection{Протокол удаленного вызова процедур (RPC)}

Взаимодействие между узлами кластера осуществляется посредством механизма удаленного вызова процедур (Remote Procedure Call, RPC). В контексте алгоритма RPC рассматривается как асинхронный примитив обмена сообщениями, который позволяет одному узлу отправить запрос другому и (возможно) получить ответ.

Спецификация Raft минималистична и требует реализации всего двух основных типов RPC пакетов для обеспечения консенсуса:
\begin{enumerate}
    \item \texttt{RequestVote RPC}: Инициируется кандидатами во время процедуры выборов для сбора голосов.
    \item \texttt{AppendEntries RPC}: Инициируется лидером. Выполняет двойную функцию: используется для репликации записей журнала и в качестве сигнала работоспособности (heartbeat) для поддержания авторитета лидера.
\end{enumerate}

Предполагается, что транспортный уровень может терять сообщения, но не повреждать их. Алгоритм предусматривает повторную отправку запросов в случае отсутствия своевременного ответа.

\subsection{Концепция эпох}

В отсутствие единых физических часов, синхронизация в Raft базируется на дискретной модели логического времени. Временная шкала разбивается на произвольные по длительности интервалы, называемые \textbf{эпохами} (в оригинальной спецификации — \textit{terms}).

Эпохи пронумерованы последовательными целыми числами. Каждая эпоха начинается с процедуры выборов, за которой, в случае успеха, следует период нормальной работы под управлением единственного лидера.

Эпохи выполняют роль логических часов, позволяя узлам детерминированно разрешать конфликты версий и обнаруживать устаревшую информацию.
\begin{itemize}
    \item Каждый узел хранит номер текущей эпохи (\texttt{currentTerm}) в стабильном хранилище (энергонезависимой памяти).
    \item При любом взаимодействии узлы обмениваются номерами текущих эпох.
    \item Если узел получает сообщение с номером эпохи, меньшим, чем его собственный, он игнорирует сообщение как устаревшее.
    \item Если узел узнает о существовании более новой эпохи, он немедленно обновляет свой \texttt{currentTerm} и переходит в подчиненное состояние (Follower).
\end{itemize}

Данный механизм гарантирует, что старые лидеры, которые могли быть изолированы сетевым экраном и не знать о перевыборах, будут немедленно нейтрализованы при восстановлении связи.

\begin{figure}[H]
	\center{\includegraphics[width=0.7\linewidth]{images/terms.png}}
	\caption{Пример деления на эпохи}
\end{figure}

\subsection{Конечный автомат состояний узла}

Поведение каждого сервера в любой момент времени определяется одним из трех взаимоисключающих состояний. Переходы между состояниями управляются событиями (приход RPC) и таймерами.

\begin{enumerate}
    \item \textbf{Последователь (Follower):}
    Пассивное состояние. Узлы в этом состоянии не отправляют запросов самостоятельно, а лишь реагируют на входящие RPC от лидеров и кандидатов. Если клиент отправляет запрос последователю, тот перенаправляет его лидеру. При запуске все узлы находятся в этом состоянии.

    \item \textbf{Кандидат (Candidate):}
    Активное переходное состояние, используемое для избрания нового лидера. Узел переходит в это состояние, если перестает получать сигналы от действующего лидера в течение заданного тайм-аута. Кандидат запрашивает голоса у остальных участников кластера.

    \item \textbf{Лидер (Leader):}
    Активное управляющее состояние. Лидер обрабатывает все клиентские запросы и реплицирует их в журналы последователей. Лидер периодически отправляет пустые сообщения \texttt{AppendEntries}, чтобы подавить таймеры выборов на других узлах и предотвратить смену эпохи.
\end{enumerate}

Диаграмма переходов обеспечивает свойство, при котором в каждый момент времени (в рамках одной эпохи) в системе может действовать не более одного лидера.

\begin{figure}[H]
	\center{\includegraphics[width=0.7\linewidth]{images/states.png}}
	\caption{Диаграмма переходов}
\end{figure}

\section{Процедура выбора лидера}

Алгоритм Raft обеспечивает наличие в системе ровно одного активного лидера в рамках каждой эпохи. Процедура выборов инициируется автоматически при возникновении подозрения на сбой текущего лидера.

\subsection{Тайм-ауты и инициация выборов}

Механизм обнаружения сбоев основан на таймерах. Каждый узел-последователь поддерживает локальный таймер ожидания.
Лидер обязан периодически отправлять последователям пустые сообщения \texttt{AppendEntries}, выполняющие роль сигналов сердцебиения (\textit{heartbeats}). При получении такого сигнала последователь сбрасывает свой таймер.

Если последователь не получает коммуникаций от лидера в течение времени $T_{election}$, он предполагает, что лидер недоступен, и начинает процесс смены власти:
\begin{enumerate}
    \item Текущая эпоха инкрементируется: $currentTerm \gets currentTerm + 1$.
    \item Узел переходит в состояние \textbf{Кандидат}.
    \item Узел голосует сам за себя ($votedFor \gets self$).
    \item Узел параллельно отправляет всем остальным участникам кластера запросы \texttt{RequestVote RPC}.
\end{enumerate}

\subsection{Спецификация запроса голосования}

Запрос голоса содержит информацию, необходимую получателю для принятия решения. Структура RPC вызова включает:
\begin{itemize}
    \item \texttt{term}: номер эпохи кандидата.
    \item \texttt{candidateId}: идентификатор кандидата.
    \item \texttt{lastLogIndex}: индекс последней записи в журнале кандидата.
    \item \texttt{lastLogTerm}: эпоха последней записи в журнале кандидата.
\end{itemize}

Последние два поля необходимы для проверки актуальности данных кандидата.

Узел-получатель голосует за кандидата (отвечает \texttt{voteGranted=true}) только при выполнении двух условий:
\begin{enumerate}
    \item Эпоха кандидата не меньше текущей эпохи получателя ($term \ge currentTerm$).
    \item В текущей эпохе узел еще не отдавал голос другому кандидату (или уже отдал его этому же кандидату).
    \item Журнал кандидата не менее актуален, чем собственный журнал получателя (сравнение по \texttt{lastLogTerm} и \texttt{lastLogIndex}).
\end{enumerate}

Принцип «один узел — один голос за эпоху» гарантирует, что большинство не может проголосовать за двух разных кандидатов одновременно.

\subsection{Завершение выборов}

Кандидат остается в этом состоянии до наступления одного из трех событий:

\textbf{1. Победа на выборах:}
Кандидат получает подтверждающие голоса от большинства узлов кластера ($N/2+1$). После этого он немедленно провозглашает себя Лидером и начинает рассылку heartbeats, чтобы подавить новые выборы и утвердить свой авторитет.

\textbf{2. Обнаружение другого лидера:}
Если в процессе ожидания голосов кандидат получает валидный RPC \texttt{AppendEntries} от другого узла с номером эпохи $T \ge currentTerm$, он признает легитимность нового лидера и возвращается в состояние Последователя.

\textbf{3. Истечение времени:}
Если голоса разделились так, что ни один кандидат не набрал большинства (ситуация «разделенного голосования»,  <<Split Vote>>), выборы завершаются без результата.

\subsection{Проблема разделения голосов и рандомизация}

В кластерах с четным числом узлов или при одновременном старте выборов несколькими кандидатами возможна ситуация, когда ни один кандидат не смог собрать большинство голосов. Без дополнительных мер кандидаты могут бесконечно перезапускать выборы, каждый раз разделяя голоса поровну.

Raft решает эту проблему путем использования \textbf{рандомизированных тайм-аутов}. Значение $T_{election}$ не фиксировано, а выбирается случайно из диапазона (например, $[150ms, 300ms]$) при каждом перезапуске таймера.
Такой разброс гарантирует, что у одного из узлов таймер истечет раньше, чем у других. Этот узел успеет инициировать выборы, отправить RPC-запросы и собрать большинство голосов до того, как другие узлы проснутся и выдвинут свои кандидатуры. Вероятность повторной коллизии при таком подходе стремится к нулю.

\section{Механизм репликации журнала}

После избрания лидер принимает на себя полную ответственность за управление реплицированным журналом. Клиенты отправляют запросы только лидеру. Нормальный режим работы системы:

\begin{enumerate}
    \item Лидер добавляет новую команду клиента в свой локальный журнал.
    \item Лидер параллельно отправляет запросы \texttt{AppendEntries RPC} всем последователям для репликации этой записи.
    \item После получения подтверждения об успешной записи от большинства узлов, лидер фиксирует команду и применяет её к своему конечному автомату и возвращает реызультат клиенту.
    \item Лидер уведомляет последователей о факте фиксации команды, после чего они также применяют её к своим автоматам.
\end{enumerate}

\subsection{Структура журнала}

Журнал представляет собой последовательный массив записей. Каждая запись содержит:
\begin{itemize}
    \item \textbf{Команда:} Операция для машины состояний (например, \texttt{x=3}).
    \item \textbf{Номер эпохи:} Логическое время создания записи. Используется для обнаружения несогласованностей.
    \item \textbf{Индекс:} Порядковый номер записи в массиве (монотонно возрастающее целое число).
\end{itemize}

\subsection{Свойство согласованности журнала}

Raft поддерживает строгий инвариант целостности журнала, который формулируется следующим образом:
\begin{enumerate}
    \item Если две записи в разных журналах имеют одинаковый индекс и эпоху, то они хранят одну и ту же команду.
    \item Если две записи в разных журналах имеют одинаковый индекс и эпоху, то все предшествующие им записи в этих журналах также идентичны.
\end{enumerate}

Первое свойство гарантируется тем, что лидер создает не более одной записи с заданным индексом в рамках одной эпохи.
Второе свойство обеспечивается индуктивной проверкой, встроенной в протокол \texttt{AppendEntries}. При отправке новой записи лидер включает в запрос параметры предыдущей записи (\texttt{prevLogIndex}, \texttt{prevLogTerm}). Последователь принимает новые данные только в том случае, если в его журнале действительно найдена такая "предыдущая" запись.

\subsection{Алгоритм восстановления согласованности}

В реальных условиях (сбои узлов, потери пакетов) журналы последователей могут рассинхронизироваться с журналом лидера. Могут возникать две ситуации:
\begin{itemize}
    \item \textbf{Отсутствующие записи:} Журнал последователя короче журнала лидера.
    \item \textbf{Лишние (незафиксированные) записи:} Журнал последователя содержит данные из старых эпох, которые не были зафиксированы и конфликтуют с историей текущего лидера.
\end{itemize}

Raft решает проблему несогласованности путем принудительной синхронизации: лидер заставляет журнал последователя дублировать свой собственный журнал.

Процедура согласования выглядит так:
1. Лидер поддерживает для каждого последователя переменную \texttt{nextIndex} — индекс следующей записи, которую он планирует отправить (изначально равен $LastIndex + 1$).
2. Лидер отправляет \texttt{AppendEntries} с данными, начиная с \texttt{nextIndex}, и указывает \texttt{prevLogIndex = nextIndex - 1}.
3. Если последователь не находит у себя запись, соответствующую \texttt{prevLogIndex}, он отклоняет запрос (возвращает \texttt{false}).
4. Получив отказ, лидер уменьшает \texttt{nextIndex} на единицу и повторяет попытку.

Этот процесс продолжается рекурсивно («алгоритм отката»), пока не будет найдена точка, в которой журналы совпадают (в худшем случае — начало журнала). Как только проверка согласованности проходит успешно, последователь удаляет все записи после точки совпадения (конфликтующий «хвост») и заменяет их записями, полученными от лидера.

\section{Гарантии безопасности и корректности}

Описанных выше механизмов выборов и репликации недостаточно для обеспечения строгой согласованности. Без дополнительных ограничений возможен сценарий, при котором лидером будет избран узел, не обладающий всей историей зафиксированных операций, что приведет к затиранию подтвержденных транзакций.

Для предотвращения подобных ситуаций Raft вводит дополнительные правила безопасности, гарантирующие полноту лидера.

\subsection{Ограничение на участие в выборах}

В большинстве алгоритмов консенсуса лидер обязан догружать недостающие данные от других участников после избрания. Raft использует альтернативный подход: он гарантирует, что узел может быть избран лидером только в том случае, если его журнал уже содержит все зафиксированные записи.

Это ограничение реализуется на этапе голосования \texttt{RequestVote}. Кандидат включает в запрос метаданные своего журнала (\texttt{lastLogTerm}, \texttt{lastLogIndex}). Узел-избиратель сравнивает эти данные со своим журналом и отказывает в голосе, если журнал кандидата менее актуален.

Сравнение производится по следующим правилам:
\begin{itemize}
    \item Если эпохи последних записей отличаются, более актуальным считается журнал с большим номером эпохи.
    \item Если эпохи равны, более актуальным считается журнал, содержащий больше записей (больший индекс).
\end{itemize}

Поскольку любая зафиксированная запись присутствует на большинстве узлов, а для победы на выборах необходимо получить голоса большинства, то в кворуме избирателей гарантированно найдется хотя бы один узел с этой записью. Этот узел откажет кандидатам с устаревшим журналом, блокируя избрание некорректного лидера.

\subsection{Правила фиксации записей}

Понятие фиксации определяет момент, когда запись считается перманентной и может быть безопасно применена к машине состояний. Лидер считает запись зафиксированной, если она успешно реплицирована на большинство серверов.

Однако существует тонкая проблема при фиксации записей из предыдущих эпох. Новый лидер, придя к власти, может обнаружить в своем журнале записи, скопированные от прошлых лидеров, но еще не зафиксированные (не набран кворум).

Raft вводит жесткое правило: лидер никогда не фиксирует записи из предыдущих эпох путем подсчета реплик. Он может считать зафиксированными только записи из \textit{своей текущей эпохи}.

Записи из старых эпох фиксируются косвенно: когда лидер успешно реплицирует и фиксирует новую запись из своего текущей эпохи, все предшествующие записи (включая старые) автоматически считаются зафиксированными по свойству согласованности журнала.
Это правило предотвращает редкий, но опасный сценарий, при котором запись из старой эпохи, реплицированная на большинство узлов, может быть перезаписана будущим лидером.

\subsection{Доказательство свойства полноты лидера}

Сформулируем ключевую теорему безопасности Raft:
\textit{Если запись была зафиксирована в какой-либо эпохе $T$, то она будет присутствовать в журнале любого лидера всех будущих эпох $U > T$.}

Доказательство (от противного):
\begin{enumerate}
    \item Пусть запись $L_{comm}$ была зафиксирована в эпохе $T$, то есть она сохранена на кворуме узлов $Q_{commit}$.
    \item Пусть $U$ — первая эпоха после $T$, в котором был избран лидер $Leader_U$, не имеющий записи $L_{comm}$.
    \item Для избрания $Leader_U$ должен был собрать голоса кворума $Q_{elect}$.
    \item Множества $Q_{commit}$ и $Q_{elect}$ имеют непустое пересечение. Следовательно, существует узел-свидетель $p$, который хранит $L_{comm}$ и при этом проголосовал за $Leader_U$.
    \item Узел $p$ мог проголосовать за $Leader_U$ только в том случае, если журнал $Leader_U$ был не менее актуален, чем журнал $p$. А это невозможно, так как у $Leader_U$ отсутствует запись $L_{comm}$, которая есть у $p$.
\end{enumerate}
Полученное противоречие доказывает невозможность утраты зафиксированных данных при смене лидера.